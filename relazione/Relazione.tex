\documentclass[12pt,openany]{report}
\def\tit{DNA Sequence}
\date{\today}
\makeatletter
\let\datename\@date
\makeatother
\def\authorname{Simone Lidonnici - (2061343)\\Marco Casu - (2041262)}



%Include------------------------------------------------
\usepackage[italian]{babel}
\usepackage{array}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage[paper=a4paper,left=20mm,right=20mm,bottom=25mm,top=25mm]{geometry}
\usepackage{graphicx}
\usepackage{bookmark}
\usepackage[listings,breakable]{tcolorbox}
\tcbuselibrary{skins}
\usepackage{fancyhdr}
\usepackage[absolute,overlay]{textpos}
%-------------------------------------------------------




%Stile pagina
\raggedbottom
\pagestyle{fancy}
\setlength{\headheight}{15pt}
\fancyhead[L]{\nouppercase{\leftmark}}
\fancyhead[R]{\ifnum\value{chapter}>0{\nouppercase{\rightmark}}\fi}
\fancyfoot[C]{\thepage}
%------------------------------------------------


\renewcommand{\thesection}{\arabic{section}}
\definecolor{Sapienza}{RGB}{131,31,48}


\begin{document}
%INIZIO PRIMA PAGINA
\begin{titlepage}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{images/Sapienza_logo.png}
    \end{center}
    \centering\Large \textbf{\color{Sapienza}{Facoltà di Ingegneria dell'Informazione, Informatica e Statistica\\Dipartimento di Informatica}}
    \vspace{4cm}
    \begin{tcolorbox}[enhanced, width=\textwidth, colframe=Sapienza, colback=white, halign=flush center, sharp corners=all, boxrule=1mm, bottom=5mm, top=5mm]
        \Huge\textbf{\tit}
    \end{tcolorbox}
    \begin{textblock*}{\textwidth}[0.5,0](0.5\pdfpagewidth,20cm)
        \centering\large\textbf{Autori:}\\\authorname
    \end{textblock*}
    \vfill
    \centering\large\datename
\end{titlepage}
%FINE PRIMA PAGINA

\section{Introduzione}
Le parti principali di codice da parallelizzare sono la creazione della sequenza e la ricerca dei pattern. Per sequenze medio-piccole quest'ultima compone la maggior parte del tempo di compilazione, mentre aumentando la grandezza della sequenza (nell'ordine dei miliardi), la maggior parte del tempo è richiesto per generare la sequenza. Da notare che nel programma sequenziale il tempo non conta la generazione di quest'ultima mentre nei programmi paralleli (MPI, OpenMP, CUDA e MPI+OpenMP) si, cosa che causa una diminuzione dello speedup.
\subsection{Test e calcolo dello speedup}
Le varie versioni del programma sono state testate sul cluster eseguendo 10 test e controllando il tempo medio di essi, scartando dal calcolo della media il caso peggiore ed il caso migliore, in particolare il test è stato eseguito con i seguenti parametri:
\begin{center}
    \texttt{500000 0.35 0.2 0.25 30000 2000 1000 30000 2000 1000 500 100 M 4353435}
\end{center}

\newpage
\section{MPI}
Nel programma MPI la ricerca dei pattern è stata distribuita uniformemente tra i rank, se $t$ è il numero dei processi, allora ognuno ricercherà $\lceil \frac{n}{t}\rceil$ pattern, con $n$ numero totale di pattern (sia sample che random). Se $\frac{n}{t}$ non è un numero intero, l'ultimo rank ricercherà meno pattern rispetto ad ogni altro. Per avere poi il valore corretto dei pattern trovati e dei pattern in ogni punto della sequenza vengono eseguite delle collettive \texttt{MPI\_Reduce} su $\texttt{seq\_matches}$ e $\texttt{pat\_found}$.

\bigskip 
Riguardo la generazione della sequenza,
è stato osservato che, questa, risulta  più veloce nella versione sequenziale, anche se viene adoperato un singolo thread, la funzione\\ \texttt{generate\_random\_sequence} impiega sempre meno tempo ad essere eseguita nella versione sequenziale piuttosto che in quella parallela.
sono stati tentati due approcci\begin{itemize}
    \item 
Si è inizialmente provato a far generare l'intera sequenza ad un solo processo, per poi eseguire una \texttt{Broadcast}, condividendola a tutti gli altri processi. Tale versione si è rivelata più veloce della versione iniziale (in cui ogni rank genera autonomamente la sequenza) ma comunque più lenta della versione sequenziale.
\item  La seconda opzione, presente nel file finale, è stata quella di dividere la sequenza tra i vari rank, nello stesso modo in cui vengono divisi i pattern e poi eseguire una $\texttt{MPI\_Allreduce}$ per far avere a tutti i rank la sequenza completa. Data la natura puramente sequenziale delle funzioni rng, ogni rank esegue un $\texttt{rng\_skip}$ per poter iniziare a generare i suoi numeri random da un punto avanzato della sequenza.\end{itemize}
Di seguito si può vedere il grafico dei tempi in relazione al numero di processi MPI, i test sono stati eseguiti con il numero massimo di processi su un nodo (32) e aumentando i nodi progressivamente:
%\includegraphics{images/tempi_MPI.pdf}
In seguito è riportato anche il grafico dello speedup:
%\includegraphics{images/speedup_MPI.pdf}
Se si vogliono consultare le informazioni in maniera più pratica, si può controllare la seguente tabella:


\newpage
\section{OpenMP}
Nel programma OpenMP per quanto riguarda la ricerca dei pattern abbiamo creato delle variabili \texttt{pat\_matches} e \texttt{seq\_matches} private per ogni thread e abbiamo parallelizzato solamente il ciclo più esterno, tramite un \texttt{\#pragma omp for}, questo perché i tre cicli non potevano essere collassati in uno unico data la presenza di \texttt{break} al loro interno.
\bigskip

Dopo il ciclo \texttt{for} relativo alla ricerca dei pattern ogni thread avrà operato sulle proprie copie private di \texttt{pat\_matches} e \texttt{seq\_matches}. Sarà necessario collossare i risultati parziali ottenuti da ogni thread, sommandone i valori.
A tal proposito, sarà necessario sequenziare una porzione di codice con la direttiva \texttt{\#pragma omp critical}, in cui ogni thread sommerà i valori di \texttt{pat\_matches} e \texttt{seq\_matches} per avere i valori finali corretti.\bigskip

Per quanto riguarda invece la creazione della sequenza abbiamo usato lo stesso approccio di MPI, cioè dividerla in parti uguali in base all'id del thread e far eseguire ad ogni thread \texttt{rng\_skip} fino al punto dove deve iniziare a generare i propri numeri random. Per impostare il numero di thread è stato aggiunto un argomento in input, in modo da poterli impostare da linea di comando.\bigskip


Di seguito si può vedere il grafico dei tempi e dello speedup in relazione al numero di thread, i test sono stati eseguiti aumentando il numero di thread progressivamente:\begin{center}
\includegraphics[width=0.5\textwidth ]{images/tempi_OpenMP.pdf}\includegraphics[width=0.5\textwidth ]{images/speedup_OpenMP.pdf}
\end{center}
Si osservi come la decrescita del tempo impiegato a terminare il programma è inizialmente esponenziale. In seguito, è riportata la tabella dei tempi e dello speed up:\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline
        \rowcolor[HTML]{EFEFEF} 
        numero di  thread & tempo     & speedup   \\ \hline
        sequenziale       & 71.273433 & 1         \\ \hline
        2                 & 36.941176 & 1.928686  \\ \hline
        4                 & 18.620522 & 3.826311  \\ \hline
        8                 & 9.486428  & 7.51051   \\ \hline
        16                & 4.841522  & 14.716016 \\ \hline
        32                & 2.939143  & 24.241052 \\ \hline
        \end{tabular}
\end{center}



\end{document}